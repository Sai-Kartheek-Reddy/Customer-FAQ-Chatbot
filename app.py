import subprocess
import sys
import random
import time

# --------------------------------------------------
# ğŸ”§ Install / upgrade dependencies silently
# --------------------------------------------------
# subprocess.check_call([
#     sys.executable,
#     "-m",
#     "pip",
#     "install",
#     "-q",
#     "-U",
#     "trl",
#     "faiss-cpu",
#     "langchain",
#     "sentence-transformers",
#     "langchain-community",
#     "streamlit",
# ])


import streamlit as st
from Backend import rag_query  # Replace "Backend" with "GBackend" to use Gemini Based Applications

# --------------------------------------------------
# ğŸ–¼ï¸ Page configuration & header
# --------------------------------------------------
st.set_page_config(
    page_title="Jupiter FAQ Chatbot",
    page_icon="ğŸ’¬",
    layout="centered",
)

st.markdown(
    """
    <h1 style='text-align: center;'>ğŸ”· Jupiter Money FAQ Chatbot</h1>
    """,
    unsafe_allow_html=True,
)

# --------------------------------------------------
# ğŸ’¾ Session state (conversation memory)
# --------------------------------------------------
if "history" not in st.session_state:
    st.session_state.history: list[tuple[str, str]] = []

# ğŸ”¹ Helpful tips we can show *during* generation
TIPS = [
    "ğŸ’¡ Tip: Ask \"How does Jupiter categorise my spending?\"",
    "ğŸ’¡ Tip: Try \"What can I do in the Money tab?\"",
    "ğŸ’¡ Tip: Wondering about rewards? Ask \"Tell me about card rewards.\"",
    "ğŸ’¡ Tip: Curious about KYC? Try \"What documents are required for KYC?\"",
]

# ğŸ”¹ Dynamic status phrases
STATUSES = [
    "ğŸ” Searching Jupiter knowledge baseâ€¦",
    "ğŸ“š Reading related FAQsâ€¦",
    "âš™ï¸ Crunching the numbersâ€¦",
    "ğŸ’¡ Generating insightsâ€¦",
    "âœï¸ Drafting a clear answerâ€¦",
    "ğŸ”„ Doubleâ€‘checking detailsâ€¦",
]

# --------------------------------------------------
# ğŸ—¨ï¸ Show conversation history
# --------------------------------------------------
st.markdown("## ")  # Spacer below header
chat_placeholder = st.container()
with chat_placeholder:
    for user_msg, bot_msg in st.session_state.history:
        with st.chat_message("user"):
            st.markdown(user_msg)
        with st.chat_message("assistant"):
            st.markdown(bot_msg)

# --------------------------------------------------
# âœï¸ Chatâ€‘input (autoâ€‘bottom)
# --------------------------------------------------
user_query: str | None = st.chat_input("Ask me anything about Jupiterâ€¦")

# --------------------------------------------------
# ğŸ¤– Generate & *stream* assistant reply
# --------------------------------------------------
if user_query:
    # âŠ Show user message immediately
    with st.chat_message("user"):
        st.markdown(user_query)

    # â‹ Prepare assistant message placeholder
    with st.chat_message("assistant"):
        message_placeholder = st.empty()

        # âŒ Build a dynamic sequence of statuses + tips
        status_sequence: list[str] = ["ğŸ¤” Thinkingâ€¦"]
        status_sequence += random.sample(STATUSES, k=3)
        status_sequence += random.sample(TIPS, k=random.randint(1, 2))
        random.shuffle(status_sequence[1:])  # shuffle everything except the very first "Thinkingâ€¦"

        for status in status_sequence:
            message_placeholder.markdown(status)
            time.sleep(random.uniform(0.5, 1.0))

        # â Call backend RAG
        response = rag_query(user_query)

        # â Liveâ€‘typing effect (wordâ€‘byâ€‘word)
        full_response = ""
        for word in response.split():
            full_response += word + " "
            message_placeholder.markdown(full_response + "â–Œ")
            time.sleep(0.04)

        # â Replace cursor â–Œ with final text
        message_placeholder.markdown(full_response)

    # â Persist interaction into session history
    st.session_state.history.append((user_query, full_response))
